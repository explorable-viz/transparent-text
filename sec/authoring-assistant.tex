\section{LLM-Based Authoring Assistant}
\label{sec:llm-based-authoring-assistant}

\subsection{Introduction}
\label{subsec:introduction}

\subsubsection{Query}
The Query represents the input provided to the AuthoringAssistant and contains all the necessary information for generating the expression in the Fluid language.
Formally, a Query is defined as a quintuple $Q = \{D^*, I^*, C, P, E\}$, where:

\begin{itemize}
    \item $D^*$ denotes the set of datasets, each represented as a pair $D = (K, V)$, where $K$ is the variable name and $V$ is the corresponding value, structured in dictionary format (JSON-like).
    \item $I^*$ represents the set of modules, where each element $I$ corresponds to a Fluid library required for the expression generation.
    \item $C$ represents the source code written in the Fluid language, serving as the context for generating the desired expression.
    \item $P$ represents the paragraph containing the placeholder tag $[REPLACE\ value=x]$, which will be replaced by the generated expression.
    \item $E$ represents the expected expression, which is necessary for computing the expected value used in result validation.
\end{itemize}

\subsubsection{AuthoringAssistant}
The AuthoringAssistant, based on a Large Language Model (LLM), processes a given query $Q$ and generates the corresponding Fluid expression, denoted as $E_{candidate}$.
The computed value of the generated expression $E_{candidate}$ must be equal to the value obtained from the expected expression $E_{query}$, the expression $E$ defined in $Q$.
This check is verified using the FluidCLI, which executes the Fluid interpreter and parses the command-line output.

\subsection{Key Use-cases}
\label{subsec:key-use-cases}

\subsubsection{Aggregation}
Operations that summarize data, including sum, average, max, and min.
Example sentences.
\begin{itemize}
    \item The average/total methane emissions for the year \$emissions.year\$ is $[REPLACE value=\$emissions.quantity\$]$
    \item In \$emissions.year\$, the $[REPLACE value=?]$ had the \$emissions.rank\$ amount in methane emissions.
\end{itemize}

\subsubsection{Trends}
Analysis of increasing or decreasing patterns in data.
Example sentence.
\begin{itemize}
    \item Between \$emissions.year1\$ and \$emissions.year2\$, methane emissions increases/decreases across most sources, with the largest absolute rise/reduction seen in  $[REPLACE value=?]$.
\end{itemize}

\subsubsection{Unknown Value}
Analyse the ability of the Assistant to generate the correct Fluid Expression without knowing the expected value (? symbol)
Example sentence.
\begin{itemize}
    \item In \$emissions.year\$, the $[REPLACE value=?]$ had the \$emissions.rank\$ amount in methane emissions.
\end{itemize}


\subsection{Candidate Research Questions}
\label{subsec:candidate-research-questions}

\subsubsection[Usability of LLM-based authoring tool vs. editing purely by hand]{Usability of LLM-based authoring tool vs. editing purely by hand}

\subsubsection{Impact of documentation and naming conventions on the output accuracy}
Analyse how the use of proper naming conventions and the inclusion of comments in each example of the
in-context learning dataset affect the accuracy of the LLM's output. \textbf{RQ}: How do documentation, naming
conventions, affect performance of LLM?

\subsubsection{Impact of Example Complexity on LLM Generalization in DSLs}
Analyse the impact of the structure of the in-context learning dataset on the accuracy of responses, with a particular focus on the complexity of datasets.
By complexity, we mean the number of Fluid elements that the in-context learning dataset contains for each example.


\textbf{Related work (links)}
\begin{itemize}
    \item \href{http://www.lrec-conf.org/proceedings/lrec-coling-2024/pdf/2024.main-1.1251.pdf}{Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment} - not strongly related to dsl, but interesting about diversity in prompt.
\end{itemize}

\textbf{RQ}: What is the impact of example complexity on the accuracy of LLM-generated outputs in DSL tasks?

\subsubsection{Analysis of the Role of Formal Models in Enhancing LLMs for DSL Generation}

Analyse the impact of formal models, such as Context-Free Grammar, on the responses generated by the LLM.

\textbf{Related work (links)}
\begin{itemize}
    \item \href{https://dl.acm.org/doi/10.1145/3652620.3687811}{From a Natural to a Formal Language with DSL Assistant.}
    \item \href{https://proceedings.neurips.cc/paper_files/paper/2023/file/cd40d0d65bfebb894ccc9ea822b47fa8-Paper-Conference.pdf}{Grammar Prompting for Domain Specific Languages}
    \item \href{https://www.sciencedirect.com/science/article/abs/pii/S0920548924001077}{Grammar-obeying program synthesis: A novel approach using large language models and many-objective genetic programming}
\end{itemize}

\textbf{RQ}: How does the integration of formal model (e.g., grammars) enhance the ability of LLMs to generate structured and domain-specific languages?

\subsubsection{Influence of LLM parameters on the accuracy}
Examine the influence of the following parameters on the accuracy of responses generated by the LLM:

\begin{itemize}
    \item Temperature
    \item num\_ctx
    \item repeat\_penalty
\end{itemize}

\textbf{RQ}: How do LLM parameters (e.g., temperature, context size) affect the accuracy of responses in domain-specific languages (DSLs)?

\textbf{Related work (links)}
\begin{itemize}
    \item \href{https://ieeexplore.ieee.org/document/10684656}{On the Effectiveness of Large Language Models in Statement-level Code Summarization.} They analysed (among other things) the effectiveness of the temperature parameter for the generation of comments, but in my opinion not in depth.
\end{itemize}
